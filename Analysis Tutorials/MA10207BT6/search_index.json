[["index.html", "Analysis 1B — Tutorial 6 Introduction", " Analysis 1B — Tutorial 6 Christian Jones: University of Bath March 2023 Introduction Here is the material to accompany the 6th Analysis 1B Tutorial on the 13th March. Alternative formats can be downloaded by clicking the download icon at the top of the page. Please send any comments or corrections to Christian Jones (caj50). To return to the homepage, click here. "],["lecture-recap.html", "1 Lecture Recap ", " 1 Lecture Recap "],["diff.html", "1.1 Rules of Differentiation", " 1.1 Rules of Differentiation Recall the definition of a derivative from last week: Definition 1.1: (Derivative) Let \\(f: D \\to \\mathbb{R}\\), where \\(D \\subseteq \\mathbb{R}\\) is an open set, and let \\(c \\in D\\). Then, if \\(\\exists L \\in \\mathbb{R}\\) such that \\[\\lim_{h \\to 0}\\frac{f(c+h) - f(c)}{h} = L\\;\\; \\left(\\text{or}\\;\\; \\lim_{x\\to c}\\frac{f(x) - f(c)}{x - c} = L\\right),\\] we say that \\(f\\) is differentiable at \\(c\\), and define \\(f&#39;(c):=L\\) to be the derivative of \\(f\\) at \\(c\\). Since everything inside the limit is just a function (of either \\(h\\) or \\(x\\)), we can apply the algebra of limits to deduce a few familiar rules of differentiation: Theorem 1.1: (Algebra of Derivatives 1) Let \\(D\\subseteq\\mathbb{R}\\) be an open set, and let \\(f,g:D \\to \\mathbb{R}\\) be differentiable at \\(c\\in D.\\) Then the following functions are differentiable at \\(c\\): \\(f+g\\), with \\[(f+g)&#39;(c) = f&#39;(c) + g&#39;(c),\\] \\(Kf\\) for any \\(K\\in\\mathbb{R}\\), with \\[(Kf)&#39;(c) = Kf&#39;(c),\\] Using these two rules we can show that the set of functions \\(f:D\\to\\mathbb{R}\\) which are differentiable at \\(c\\) form a vector space. In fact, since differentiability implies continuity, and the zero function \\(0:D \\to \\mathbb{R}\\) given by \\(0(x) = 0\\) is also differentiable at \\(c\\), this set forms a vector subspace of the set of functions \\(f:D \\to \\mathbb{R}\\) which are continuous at \\(c\\). There are three further rules which make up the Algebra of Derivatives: Theorem 1.2: (Algebra of Derivatives 2) Let \\(D\\subseteq\\mathbb{R}\\) be an open set, and let \\(f,g:D \\to \\mathbb{R}\\) be differentiable at \\(c\\in D.\\) Then the following functions are differentiable at \\(c\\): (Product rule) \\(fg\\), with \\[(fg)&#39;(c) = f&#39;(c)g(c) + f(c)g&#39;(c),\\] For \\(g(c)\\neq0\\), \\(1/g\\), with \\[\\left(\\frac{1}{g}\\right)&#39;(c) = \\frac{-g&#39;(c)}{g(c)^2}.\\] (Quotient rule) For \\(g(c)\\neq0\\), \\(f/g\\) with \\[\\left(\\frac{f}{g}\\right)&#39;(c) = \\frac{f&#39;(c)g(c)-f(c)g&#39;(c)}{g(c)^2}.\\] One thing to note here is that we can obtain the quotient rule by applying the product rule to the functions \\(f\\) and \\(1/g\\), which saves you having to learn the proof! 1.1.1 Chain Rule The one thing we’ve said nothing about so far is whether a composition of functions is differentiable. This result is what is known as the (familiar) chain rule: Theorem 1.3: (Chain Rule) Let \\(g:(a,b) \\to \\mathbb{R}\\) and \\(f:(A,B) \\to \\mathbb{R}\\) be such that \\(g\\left((a,b)\\right) \\subseteq (A,B).\\) Assume that \\(g\\) is differentiable at \\(c\\) and \\(f\\) is differentiable at \\(g(c)\\). Then the composition \\(f\\circ g\\) is differentiable at \\(c\\) with \\[\\left(f\\circ g\\right)&#39;(c) = f&#39;\\left(g(c)\\right)g&#39;(c).\\] "],["inverse-functions.html", "1.2 Inverse Functions", " 1.2 Inverse Functions Another thing we might want to know is whether we can differentiate the inverse of a differentiable function. For example, the exponential function \\(\\exp\\) and the trigonometric functions \\(\\sin, \\cos\\) have nice series definitions, and this makes it fairly straightforward to calculate their derivatives. But what if we’re interested in their inverses (\\(\\ln, \\arcsin, \\arccos\\))? Luckily, we have a theorem which tells us what the values of their derivatives are! Theorem 1.4: (Inverse Function Theorem) Let \\(f: (a,b) \\to (A, B)\\) be bijective, and let \\(c \\in (a,b).\\) Assume that \\(f\\) is differentiable at \\(c\\), \\(f&#39;(c) \\neq 0\\), and \\(f^{-1}\\) is continuous at \\(f(c).\\) Then \\(f^{-1}\\) is differentiable at \\(y_0 = f(c)\\) and \\[\\left(f^{-1}\\right)&#39;(y_0) = \\frac{1}{f&#39;\\left(f^{-1}(y_0)\\right)} = \\frac{1}{f&#39;(c)}.\\] Example 1.1: Returning to our exponential example from last week, we know that from lectures \\(\\exp: \\mathbb{R} \\to (0,\\infty)\\) is differentiable for all \\(c \\in \\mathbb{R}\\), and since \\(\\exp&#39;(x) = \\exp(x)\\), \\(\\exp&#39;(c) \\neq 0\\) for any \\(c\\). Last week, we showed that the inverse function \\(\\ln: (0,\\infty) \\to \\mathbb{R}\\) is continuous at any \\(\\exp(c) \\in (0,\\infty)\\), so by Theorem 1.4, \\(\\ln\\) is differentiable on \\((0,\\infty)\\), with \\[\\ln&#39;(y_0) = \\frac{1}{\\exp&#39;(\\ln(y_0))} = \\frac{1}{\\exp(\\ln(y_0))} = \\frac{1}{y_0}.\\] Graphically, we can see the result of this theorem by comparing the gradient of the associated tangent lines: ADD GRAPH We can use the results of Example 1.1 and the rules of differentiation from Section 1.1 to calculate the derivatives of some more complicated functions: Example 1.2: Consider the function \\(h:(0,\\infty) \\to (0,\\infty)\\) given by \\(h(x) = x^x.\\) Since \\[h(x) = \\exp(\\ln(x^x)) = \\exp(x\\ln(x)),\\] we can rewrite \\(h\\) as a composition of differentiable functions \\(h = f \\circ g\\), where \\(f:\\mathbb{R} \\to (0,\\infty)\\) is defined by \\(f(x) = \\exp(x)\\), and \\(g: (0,\\infty) \\to \\mathbb{R}\\) is defined by \\(g(x) = x\\ln(x).\\) From lectures, we know that \\(f\\) is differentiable on \\(\\mathbb{R}\\) with \\(f&#39;(x) = \\exp(x).\\) Furthermore, by Example 1.1 and the product rule, we know that \\(g\\) is differentiable on \\((0,\\infty)\\), with \\(g&#39;(x) = \\ln(x) + 1.\\) Hence, by the chain rule, \\(h\\) is differentiable on \\((0,\\infty)\\) with \\[h&#39;(x) = f&#39;(g(x))g&#39;(x) = \\exp(x\\ln(x))\\left(\\ln(x) + 1\\right) = x^x\\left(\\ln(x) + 1\\right)\\] Theorem 1.4 will come in handy if you ever need to perform coordinate transforms, in particular when evaluating integrals by substitution. You may have also come across the multivariate version of this theorem in MA10230 (Multivariable Calculus and Differential Equations) when calculating the Jacobian for a transformation from Cartesian to polar coordinates (or vice versa). "],["hints.html", "2 Hints", " 2 Hints As per usual, here’s where you’ll find the problem sheet hints! We did some examples similar to this in the tutorial today. Specify the domain of each function, and use the results you’ve seen in the course to justify differentiability on each domain. In regards to computing the derivatives, I don’t think you’ll have too much trouble, but let me know if you run into problems. The following formula may come in handy:\\[\\max(f(x),g(x)) = \\frac{1}{2}\\left(\\lvert f(x) - g(x) \\rvert + f(x) + g(x)\\right).\\] For the function examples, try and find \\(f,g\\) such that \\[\\max(f(x),g(x)) = \\lvert x \\rvert.\\] Using \\(p(x) = (x-a)q(x)\\), what does \\(p&#39;(x)\\) give you? "]]
