[["index.html", "Analysis 1B — Tutorial 6 Introduction", " Analysis 1B — Tutorial 6 Christian Jones: University of Bath March 2023 Introduction Here is the material to accompany the 6th Analysis 1B Tutorial on the 13th March. Alternative formats can be downloaded by clicking the download icon at the top of the page. Please send any comments or corrections to Christian Jones (caj50). To return to the homepage, click here. "],["lecture-recap.html", "1 Lecture Recap ", " 1 Lecture Recap "],["rules-of-differentiation.html", "1.1 Rules of Differentiation", " 1.1 Rules of Differentiation Recall the definition of a derivative from last week: Definition 1.1: (Derivative) Let \\(f: D \\to \\mathbb{R}\\), where \\(D \\subseteq \\mathbb{R}\\) is an open set, and let \\(c \\in D\\). Then, if \\(\\exists L \\in \\mathbb{R}\\) such that \\[\\lim_{h \\to 0}\\frac{f(c+h) - f(c)}{h} = L\\;\\; \\left(\\text{or}\\;\\; \\lim_{x\\to c}\\frac{f(x) - f(c)}{x - c} = L\\right),\\] we say that \\(f\\) is differentiable at \\(c\\), and define \\(f&#39;(c):=L\\) to be the derivative of \\(f\\) at \\(c\\). Since everything inside the limit is just a function (of either \\(h\\) or \\(x\\)), we can apply the algebra of limits to deduce a few familiar rules of differentiation: Theorem 1.1: (Algebra of Derivatives) Let \\(D\\subseteq\\mathbb{R}\\) be an open set, and let \\(f,g:D \\to \\mathbb{R}\\) be differentiable at \\(c\\in D.\\) Then the following functions are differentiable at \\(c\\): \\(f+g\\), with \\[(f+g)&#39;(c) = f&#39;(c) + g&#39;(c),\\] \\(Kf\\) for any \\(K\\in\\mathbb{R}\\), with \\[(Kf)&#39;(c) = Kf&#39;(c),\\] (Product rule) \\(fg\\), with \\[(fg)&#39;(c) = f&#39;(c)g(c) + f(c)g&#39;(c),\\] For \\(g(c)\\neq0\\), \\(1/g\\), with \\[\\left(\\frac{1}{g}\\right)&#39;(c) = \\frac{-g&#39;(c)}{g(c)^2}.\\] (Quotient rule) For \\(g(c)\\neq0\\), \\(f/g\\) with \\[\\left(\\frac{f}{g}\\right)&#39;(c) = \\frac{f&#39;(c)g(c)-f(c)g&#39;(c)}{g(c)^2}.\\] One thing to note here is that we can obtain the quotient rule by applying the product rule to result four above, which saves you having to learn the proof! Algebra Link Using rules 1 and 2 above (and the definitions of function addition and scalar multiplication), we can show that the set of functions \\(f:D\\to\\mathbb{R}\\) which are differentiable at \\(c\\) form a vector space. In fact, since differentiability implies continuity, and the zero function \\(0:D \\to \\mathbb{R}\\) given by \\(0(x) = 0\\) is also differentiable at \\(c\\), this set forms a vector subspace of the set of functions \\(f:D \\to \\mathbb{R}\\) which are continuous at \\(c\\). 1.1.1 Chain Rule The one thing we’ve said nothing about so far is whether a composition of functions is differentiable. This result is what is known as the (familiar) chain rule: Theorem 1.2: (Chain Rule) Let \\(g:(a,b) \\to \\mathbb{R}\\) and \\(f:(A,B) \\to \\mathbb{R}\\) be such that \\(g\\left((a,b)\\right) \\subseteq (A,B).\\) Assume that \\(g\\) is differentiable at \\(c\\) and \\(f\\) is differentiable at \\(g(c)\\). Then the composition \\(f\\circ g\\) is differentiable at \\(c\\) with \\[\\left(f\\circ g\\right)&#39;(c) = f&#39;\\left(g(c)\\right)g&#39;(c).\\] "],["inverse-functions.html", "1.2 Inverse Functions", " 1.2 Inverse Functions Another thing we might want to know is whether we can differentiate the inverse of a differentiable function. For example, the exponential function \\(\\exp\\) and the trigonometric functions \\(\\sin, \\cos\\) have nice series definitions, and this makes it fairly straightforward to calculate their derivatives. But what if we’re interested in their inverses (\\(\\log, \\arcsin, \\arccos\\))? Luckily, we have a theorem which tells us what the values of their derivatives are! Theorem 1.3: (Inverse Function Theorem) Let \\(f: (a,b) \\to (A, B)\\) be bijective, and let \\(c \\in (a,b).\\) Assume that \\(f\\) is differentiable at \\(c\\), \\(f&#39;(c) \\neq 0\\), and \\(f^{-1}\\) is continuous at \\(f(c).\\) Then \\(f^{-1}\\) is differentiable at \\(y_0 = f(c)\\) and \\[\\left(f^{-1}\\right)&#39;(y_0) = \\frac{1}{f&#39;\\left(f^{-1}(y_0)\\right)} = \\frac{1}{f&#39;(c)}.\\] This theorem will come in handy if you ever need to perform coordinate transforms, in particular when evaluating integrals by substitution. You may have also come across the multivariate version of this theorem in MA10230 (Multivariable Calculus and Differential Equations) when calculating the Jacobian for a transformation from Cartesian to polar coordinates (or vice versa). "],["hints.html", "2 Hints", " 2 Hints As per usual, here’s where you’ll find the problem sheet hints! We did some examples similar to this in the tutorial today. Specify the domain of each function, and use the results you’ve seen in the course to justify differentiability on each domain. In regards to computing the derivatives, I don’t think you’ll have too much trouble, but let me know if you run into problems. The following formula may come in handy:\\[\\max(f(x),g(x)) = \\frac{1}{2}\\left(\\lvert f(x) - g(x) \\rvert + f(x) + g(x)\\right).\\] For the function examples, try and find \\(f,g\\) such that \\[\\max(f(x),g(x)) = \\lvert x \\rvert.\\] Using \\(p(x) = (x-a)q(x)\\), what does \\(p&#39;(x)\\) give you? "]]
