[["index.html", "Analysis 1A — Tutorial 10 Introduction", " Analysis 1A — Tutorial 10 Christian Jones: University of Bath December 2023 Introduction Here is the material to accompany the Analysis Tutorial in Week 10. Alternative formats can be downloaded by clicking the download icon at the top of the page. As usual, send comments and corrections to Christian Jones (caj50). To return to the homepage, click here. "],["lecture-recap.html", "1 Lecture Recap ", " 1 Lecture Recap "],["two-more-convergence-tests.html", "1.1 Two More Convergence Tests", " 1.1 Two More Convergence Tests So far, we’ve seen two tests which allow us (under certain conditions) to determine whether a series is convergent or not. These were the comparison test and d’Alembert’s ratio test. There’s two more tests to cover here. The first is yet another thing named after Cauchy! The second concerns series which have alternating terms. This is due to Leibniz, who — depending on your point of view — is considered to be the inventor of calculus. 1.1.1 Cauchy Condensation Test This test is very good when the terms of a series involve logarithms, and can also be used to show that \\[\\sum_{n = 1}^{\\infty} \\frac{1}{n^{\\alpha}} \\;\\;\\text{converges} \\Longleftrightarrow \\alpha &gt; 1.\\] Theorem 1.1: (Cauchy) Assume \\((a_n)_n\\) satisfies \\(a_n \\geq 0 \\; \\forall n \\in \\mathbb{N}\\), and is a decreasing sequence. For \\(k \\in \\mathbb{N}\\), define \\(b_k := 2^ka_{2^k}\\). Then \\[\\sum_{n = 1}^{\\infty} a_n \\;\\; \\text{converges}\\; \\Longleftrightarrow\\; \\sum_{k = 1}^{\\infty} b_k \\;\\; \\text{converges}.\\] We conclude this (rather short) subsection with a link to an example of the Cauchy condensation test in practice. It’s highly unlikely you’ll ever get something like this in the exam, but the numbers involved are so ridiculous it’s worth including here nonetheless! 1.1.2 Leibniz Alternating Series Test We’ve stated in tutorials that the series \\[\\sum_{i=1}^{\\infty}\\frac{(-1)^n}{n}\\] is conditionally convergent — that is, that this sum converges, but \\[\\sum_{i=1}^{\\infty}\\left\\lvert\\frac{(-1)^n}{n}\\right\\rvert = \\sum_{i=1}^{\\infty}\\frac{1}{n}\\] does not. But how do we prove this? The answer to this lies within the following convergence test: Theorem 1.2: (Leibniz Alternating Series Test) Suppose \\((a_n)_{n\\in\\mathbb{N}}\\) is a decreasing sequence tending to \\(0\\) as \\(n \\to \\infty\\). Then \\[\\sum_{n=1}^{\\infty} (-1)^n a_n\\] is a convergent series. Moreover, since the sequence \\((a_n)_n\\) is decreasing towards \\(0\\), we can say that the value of this sum lies in between \\(-a_1\\) and \\(a_2 - a_1\\). "],["multiplying-series.html", "1.2 Multiplying Series", " 1.2 Multiplying Series Recall the statement of the Algebra of Series: Theorem 1.3: (Algebra of Series) Let \\(\\sum_{n=1}^{\\infty}a_n\\) and \\(\\sum_{n=1}^{\\infty}b_n\\) be convergent series, and let \\(\\alpha, \\beta \\in \\mathbb{R}\\). Then \\[\\sum_{n=1}^{\\infty}(\\alpha a_n + \\beta b_n) = \\alpha\\sum_{n=1}^{\\infty}a_n + \\beta\\sum_{n=1}^{\\infty}b_n.\\] Now, compare this to the statement of the Algebra of Limits. Notice that we’ve suspiciously omitted any mention about multiplying infinite series together. This is because while for convergent sequences \\((x_n)_n\\) and \\((y_n)_n\\), \\[\\lim_{n\\to\\infty}(x_ny_n) = \\lim_{n\\to\\infty}x_n \\cdot \\lim_{n\\to\\infty}y_n,\\] it does not follow that for convergent series \\(\\sum_{n=1}^{\\infty}a_n\\) and \\(\\sum_{n=1}^{\\infty}b_n\\), \\[\\sum_{n=1}^{\\infty} a_nb_n = \\left(\\sum_{n=1}^{\\infty}a_n\\right)\\left(\\sum_{n=1}^{\\infty}b_n\\right).\\] If you’re not convinced, we can try this with \\(a_n = b_n = \\frac{(-1)^{n}}{\\sqrt{n}}\\). Using the Leibniz test, we can see that both \\(\\sum_{n=1}^{\\infty}a_n\\) and \\(\\sum_{n=1}^{\\infty}b_n\\) converge, but \\[\\sum_{n=1}^{\\infty} a_nb_n = \\sum_{n=1}^{\\infty}\\frac{1}{n} = \\infty.\\] So, the next question we need to ask is whether a formula for multiplying convergent series exists, and if so, which series can we apply it to. This question was answered by Cauchy1, and is summarised in the below theorem: Theorem 1.4: (Cauchy Multiplication Theorem) Assume that the real series \\(\\sum_{n=0}^{\\infty}a_n\\) and \\(\\sum_{n=0}^{\\infty}b_n\\) converge absolutely, and for \\(n \\in \\mathbb{N}\\), define \\[c_n:=\\sum_{j=0}^{n}a_j b_{n - j}.\\] Then \\(\\sum_{n=0}^{\\infty} c_n\\) converges absolutely, and \\[\\sum_{n=0}^{\\infty} c_n = \\left(\\sum_{n=0}^{\\infty}a_n\\right)\\left(\\sum_{n=0}^{\\infty}b_n\\right).\\] Note that we index the sums starting at \\(n=0\\) here. This is purely for convenience, and you could equally formulate this theorem for sums starting at \\(n=1\\) (or any other value of \\(n\\) for that matter). Furthermore, we require the condition that the two individual sums are absolutely convergent. As you’ve seen in lectures, the Cauchy Multiplication Theorem will fail if the series involved are only conditionally convergent. If you’re keeping track, this is the third time Cauchy has appeared in this course.↩︎ "],["hints.html", "2 Hints", " 2 Hints As per usual, here’s where you’ll find the problem sheet hints! In this one, remember what we did in tutorials. One uses Leibniz, one can be done with Leibniz (but its quicker not to), and one diverges. Make sure you check the hypotheses of any test you use! Work out an expression for \\(\\frac{a_{n+1}}{a_n}\\) (this will depend on whether \\(n\\) is odd or even). Check whether \\((a_n)\\) is an increasing or decreasing sequence first: this will help you calculate the \\(\\limsup\\). To begin here, you’ve seen a similar trick for the square roots in previous problem sheets. Think about your tests for convergence again on this one! Use the alternative characterisation of suprema (Theorem 3.2 in the lecture notes). "]]
